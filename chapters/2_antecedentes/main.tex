\graphicspath{{chapters/2_antecedentes/figures/}}

\chapter{Revisión de antecedentes}

% Idea:
% 1. ¿Qué es la luz?
% 2. Unidades de luz
% 3. Iluminación local y global
% 4. BRDF
% 5. Trazado de rayos
% 6. Trazado de conos
% 7. Photon Mapping
% 8. Vóxeles (acá van a haber integrales, rendering científico)
% 9. Octrees
% 10. Ducto gráfico
% ... no se si esto va acá ...
% 11. Teoría de pre-filtrado
% 12. Ray marching

En este capítulo se explican en detalle los conceptos teóricos y los antecedentes más importantes para entender el algoritmo de \textit{voxel cone tracing} y la implementación desarrollada.

En las secciones \ref{sec:what-is-light} y \ref{sec:radiometry} se introducen principios básicos de la luz.
Posteriormente, se explican los fundamentos de la iluminación global en \ref{sec:local_vs_global} y \ref{sec:brdf}.

A continuación, se describen algunos métodos destacados para lograr iluminación global, como el trazado de rayos, trazado de conos y mapeo de fotones en \ref{sec:ray-tracing}, \ref{sec:historical-cone-tracing} y \ref{sec:photon-mapping}, respectivamente.

Luego se ven las primitivas usadas en el algoritmo para reducir la complejidad computacional, en \ref{sec:voxels} y \ref{sec:octree}.
Finalmente, el capítulo concluye discutiendo las herramientas de programación para GPU disponibles en \ref{sec:graphics-pipeline}.

\section{¿Qué es la luz?}\label{sec:what-is-light}

Antes de definir el problema de la iluminación global en computación gráfica y hablar de diversos trabajos que se han realizado al respecto, conviene dar un paso atrás y preguntarse, ¿qué es la luz?
La pregunta es relevante porque, más allá de las variaciones, la gran mayoría de técnicas de iluminación global se basan en modelar físicamente la luz.

En el libro \textit{Physically Based Rendering}, de Pharr, Jakob y Humphreys \cite[p.~177]{pbr}, se brinda una explicación clara y resumida de la historia de la interacción entre los humanos y la luz.

La percepción a partir de la luz es central para nuestra existencia.
La incógnita de la naturaleza de la luz ha ocupado las mentes de grandes filósofos y físicos desde el comienzo de los tiempos.
La antigua escuela filosófica hinduista de Vaisheshika (siglos VI a V antes de cristo) veía a la luz como una colección de pequeñas partículas viajando a través de rayos a una alta velocidad.
Por otra parte, en el siglo V antes de cristo, el filósofo griego Empédocles postulaba que un fuego divino emergía de los ojos humanos y combinado con los rayos de luz del sol producía visión.

Entre los siglos XVIII y XIX, eruditos como Isaac Newton, Thomas Young y Augustin-Jean Fresnel desarrollaron teorías conflictivas, donde algunas modelaban la luz como consecuencia de la propagación de ondas, y otras de partículas.
Al mismo tiempo, André-Marie Ampère, Joseph-Louis Lagrange, Carl Friedrich Gauß y Michael Faraday investigaban las relaciones entre electricidad y magnetismo que culminaron en la repentina y dramática unificación de James Clerk Maxwell en una teoría combinada conocida como \textbf{electromagnetismo} \cite{maxwell-equations}.

La luz es una manifestación con propiedades de onda.
El movimiento de partículas eléctricamente cargadas, como electrones dentro del filamento de una bombilla, produce un disturbio en un campo eléctrico circundante que se propaga hacia fuera de la fuente.
La oscilación eléctrica también produce una oscilación secundaria de un campo magnético, que a su vez refuerza la oscilación del campo eléctrico, y así sucesivamente.
La interacción entre estos dos campos da lugar a una onda que se autopropaga y puede viajar distancias extremadamente largas.
Una representación de esto se puede ver en la Figura \ref{fig:electromagnetic-wave}, en la que el campo eléctrico (azul) y el magnético (rojo) son perpendiculares el uno al otro y se propagan, avanzando a lo largo de un eje central.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{electromagnetic_wave.png}
    \caption{Representación de una onda electromagnética propagándose por el espacio.}
    \label{fig:electromagnetic-wave}
\end{figure}

A principios del siglo XX, los trabajos liderados por Max Planck, Max Born, Erwin Schrödinger y Werner Heisenberg condujeron a otro cambio sustancial en el entendimiento de la luz.
A nivel microscópico, las propiedades elementales como energía y momento solo pueden existir como un múltiplo entero de una cantidad base conocida como un \textbf{cuanto}.
En el caso de las oscilaciones electromagnéticas, este cuanto se conoce como \textbf{fotón}.
La luz existe tanto como onda y como partícula \cite{quantum-light}.

Afortunadamente, el complejo comportamiento de onda de la luz aparece en escalas muy pequeñas, por lo que, para la computación gráfica, en la mayoría de los casos se la puede tratar como partícula, lo que simplifica los cálculos \cite[p.~303]{rtr}.

Tratar a la luz como una partícula es el campo de la óptica geométrica, en contraposición a la óptica física.
La óptica geométrica trata a la luz como rayos que se mueven en líneas rectas.
La óptica física aborda la luz desde el punto de vista de su naturaleza ondulatoria, centrándose en fenómenos como la interferencia, la difracción y la polarización.
Dado que las irregularidades de las superficies son en general mucho más grandes que la longitud de onda de la luz, estos efectos no ocurren, y se puede tratar la luz como rayos \cite[p.~303]{rtr}.
A su vez, se ignoran otros fenómenos como la fluorescencia y la fosforescencia.

Para simular la luz adecuadamente, es necesario un manejo de las unidades básicas involucradas.
Este es el foco de la siguiente sección.

% Esto asume varias otras cosas, como linealidad, conservación de la energía, falta de polarización, fluorescencia y fosforescencia, entre otros.

\section{Radiometría: Unidades de la luz}\label{sec:radiometry}

La radiometría provee una serie de herramientas para describir la propagación de la luz.
Algunas de estas son la energía radiante, el flujo radiante, la radiosidad, la irradiancia, la intensidad radiante y la radiancia.
La descripción de estas unidades surgen de \cite[p.~268]{rtr} y \cite[p.~177]{pbr}.

La \textbf{energía radiante} es la energía de la radiación electromagnética de la luz.
Se mide en joules y se denota con el símbolo $Q$.
Las fuentes luminosas emiten fotones.
Cada uno posee una longitud de onda y una energía particular.
Un fotón con longitud de onda $\lambda$ tiene una energía $Q = \frac{hc}{\lambda}$, donde $c$ es la velocidad de la luz y $h$ es la constante de Planck.

El \textbf{flujo radiante}, o potencia, es la energía que pasa por una superficie o región del espacio por unidad de tiempo: $\Theta = \frac{dQ}{dt}$.
Se mide en joules por segundo, o watts.
En la Figura \ref{fig:point-light-flux} se representa en 2D una luz puntual emitiendo fotones en todas las direcciones.
Los círculos de la figura son áreas en las que se mide el flujo radiante que pasa por ellas.
Por cada círculo pasa el mismo flujo radiante, dado que la energía y el tiempo son los mismos.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.25\textwidth]{point-light-flux.png}
    \caption{Flujo radiante en una luz puntual}
    \label{fig:point-light-flux}
\end{figure}

Es útil también considerar el área por la cual pasa un flujo radiante.
Esta cantidad se llama o \textbf{radiosidad} o \textbf{irradiancia} dependiendo de si el flujo está llegando o saliendo de una superficie respectivamente.
Se define como flujo radiante por unidad de área: $E = \frac{\Theta}{A}$.
Estas medidas tienen como unidad watts por metro cuadrado.
En la Figura \ref{fig:point-light-flux}, la irradiancia en el círculo externo es menor que en el interno, dado que el área aumenta cuadráticamente con la distancia.

Para definir la próxima unidad, es necesario definir el \textbf{ángulo sólido}, que es la extensión a 3D del ángulo bidimensional.
En 2D, un ángulo mide el tamaño de un conjunto continuo de direcciones en un plano.
Para medir esto, se mide el largo del arco resultante de la intersección de este conjunto con un círculo de radio 1.
El largo de este arco se mide en radianes.
De igual manera, un ángulo sólido mide el tamaño de un conjunto de direcciones en el espacio.
Para lograrlo, se mide el área de la intersección del conjunto de direcciones con una esfera de radio 1.
La unidad de medida es el estereorradián, cuyo símbolo es \textit{sr}.
El ángulo sólido se representa con el símbolo $\omega$.
En la Figura \ref{fig:steradian} se puede ver un cono con un ángulo sólido de 1 sr.
El ángulo sólido que abarca todas las direcciones posibles mide $4\pi$ sr.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.4\textwidth]{steradians.png}
    \caption{Un cono con un ángulo sólido de 1 sr removido de una esfera. Fuente: \cite{rtr}.}
    \label{fig:steradian}
\end{figure}

La \textbf{intensidad radiante} es el flujo radiante dado un ángulo sólido.
Se denota $I(\omega) = \frac{d\Theta}{d\omega}$ y se mide en watts por estereorradián ($W sr^{-1}$).

La \textbf{radiancia} es la unidad radiométrica más importante.
Es lo que miden los sensores, como los ojos o cámaras.
Se trata de la cantidad de flujo radiante emitida, reflejada, transmitida o recibida por una superficie por unidad de área y por unidad de ángulo sólido.
Se denota como $L$ y se mide en watts por metro cuadrado por estereorradián ($W m^{-2} sr^{-1}$).

El objetivo de evaluar una ecuación de sombreado es calcular la radiancia a lo largo de un rayo, desde el punto de vista de la cámara.

La radiometría trata únicamente con cantidades físicas de la luz.
En contraposición, un campo relacionado, la fotometría, mide la luz tal como es percibida por el ojo humano, teniendo en cuenta la sensibilidad de este a distintas longitudes de onda.
En el Cuadro \ref{table:light_units} se muestran algunas unidades equivalentes en radiometría y fotometría.

\begin{table}
\centering
\begin{tabular}{|c|c|}
    \hline
    \textbf{Radiometría (unidad)} & \textbf{Fotometría (unidad)} \\
    \hline
    Flujo radiante ($W$) & Flujo luminoso ($lumen, lm$) \\
    \hline
    Radiosidad $\left(\frac{W}{m^2}\right)$ & Emitancia luminosa $\left(\frac{lm}{m^2} = lux, lx\right)$ \\
    \hline
    Irradiancia $\left(\frac{W}{m^2}\right)$ & Iluminancia ($lx$) \\
    \hline
    Intensidad radiante $\left(\frac{W}{sr}\right)$ & Intensidad luminosa ($candela, cd$) \\
    \hline
    Radiancia $\left(\frac{W}{(m^2sr)}\right)$ & Luminancia $\left(\frac{cd}{m^2} = nit\right)$ \\
    \hline
\end{tabular}
\caption{Unidades de radiometría y fotogrametría.}
\label{table:light_units}
\end{table}

En la siguiente sección se define el concepto de iluminación global utilizando estas unidades.

\section{Iluminación local e iluminación global}\label{sec:local_vs_global}

En computación gráfica, la iluminación es crucial para agregar realismo a una escena.
Sin embargo, es también uno de los aspectos más desafiantes desde el punto de vista computacional, debido a la complejidad de simular cómo la luz interactúa con los objetos y el entorno.

\subsection{Iluminación local}

La iluminación local \cite[p.~375]{rtr} es un enfoque más simple y menos demandante computacionalmente, que ayuda a dar una sensación de tridimensionalidad.
Consiste en calcular la iluminación directa para cada objeto individualmente, sin considerar la iluminación indirecta que existe entre objetos vecinos.
Al no calcular la interacción de la luz con otros objetos, se simplifican significativamente los cálculos necesarios para generar la imagen.

Sus ventajas son su simplicidad y su eficiencia.
Su mayor desventaja es que no abarca fenómenos como la refracción, las cáusticas y el sangrado, entre otros.

Un modelo ampliamente utilizado para iluminación local es el de Blinn-Phong \cite{blinn-phong}, que posee tres componentes principales: luz \textbf{ambiente}, \textbf{difusa} y \textbf{especular}.
La luz ambiente es uniforme y está presente en toda la escena.
No proviene de una fuente de luz en particular y simula el efecto de la luz indirecta que proviene del resto de la escena.
La luz difusa representa el efecto de la luz directa que incide sobre una superficie rugosa y se refleja en todas las direcciones.
Depende del ángulo entre la dirección de la luz y la normal de la superficie.
La luz especular depende de la dirección de vista, de la normal de la superficie y de la dirección de la fuente luminosa en cada punto de la superficie.
Simula el brillo que se ve cuando la luz se refleja sobre superficies pulidas.
En la Figura \ref{fig:sphere-blinn-phong} se puede observar este sombreado aplicado a una esfera.

\begin{figure}
    \begin{center}
    \begin{subfigure}{.49\textwidth}
        \includegraphics[width=\textwidth]{sphere-unshaded.png}
        \caption{Sin sombreado.}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \includegraphics[width=\textwidth]{sphere-diffuse.png}
        \caption{Con sombreado difuso.}
    \end{subfigure}
    % TODO: Agregar una foto que mezcle difuso con especular.
    \captionof{figure}{Esfera iluminada mediante el módelo local de Blinn-Phong.}
    \label{fig:sphere-blinn-phong}
    \end{center}
\end{figure}

\subsection{Iluminación global}

En contraposición a la iluminación local, la iluminación global calcula la interacción completa de la luz con los objetos de la escena.
Se calcula la interacción de la luz entre distintos objetos al reflejarse, refractarse y dispersarse en el entorno.

Su principal ventaja es la mejora en el realismo y coherencia de la escena.
Su principal desventaja es la exigencia computacional y complejidad al implementar y optimizar, que causa dificultades en alcanzar tiempos interactivos.

Entre las técnicas más utilizadas se encuentra el trazado de rayos, la radiosidad \cite[p.~442]{rtr}, el \textit{photon mapping} \cite{photon-mapping}, y el \textit{path tracing} \cite{rendering-equation}, que serán presentadas a continuación.

En 1986, James T. Kajiya presentó la \textbf{ecuación de renderizado}, formalizando varios métodos para el cálculo de iluminación global como aproximaciones a la solución de una misma ecuación, \cite{rendering-equation}:

\begin{equation}\label{eq:rendering-equation}
    I(x, x') = g(x, x') \cdot \left[\epsilon(x, x') + \int_S f(x, x', x'') \cdot I(x', x'') \cdot dx'' \right]
\end{equation}

donde:
\begin{itemize}
    \item $I(x, x')$ se relaciona con al intensidad radiante que pasa del punto $x'$ al punto $x$.
    \item $g(x, x')$ es un término de "geometría", evalúa si hay algo interponiéndose en el camino de $x'$ a $x$.
    \item $\epsilon(x, x')$ se relaciona con la intensidad emitida desde $x'$ en dirección a $x$.
    \item $f(x, x', x'')$ es la función de distribución de reflectancia bidireccional (BRDF, por sus siglas en inglés). Se relaciona con la intensidad de luz reflejada desde $x''$ hacia $x$ a través de $x'$. En la Sección \ref{sec:brdf} se analizan casos particulares de esta función.
    \item $S = \cup{S_i}$, el dominio de la integral, es la unión de todas las superficies de la escena. Los puntos $x, x', x''$ varían a lo largo de todas las superficies.
\end{itemize}

En palabras, la Ecuación \ref{eq:rendering-equation} establece que la intensidad que llega a un punto $x$ desde otro punto $x'$, es la intensidad que $x'$ emite en dirección a $x$ más la intensidad reflejada por $x'$ hacia $x$ desde cualquier otro punto de la escena ($x''$).
Todo sujeto a si hay geometría en el camino de $x$ a $x'$, si es que $x'$ ``ve'' a $x$.

Los términos ``intensidad radiante'' e ``intensidad emitida'' tal y como son planteados no son exactamente ninguna de las unidades radiométricas vistas en la Sección \ref{sec:radiometry} pero pueden derivarse de estas.

La Ecuación \ref{eq:rendering-equation} es la base de varios métodos de iluminación global \cite[p.~437]{rtr}.
Tiene en cuenta toda la escena para calcular la luz en un punto.
La misma no presenta una solución analítica cerrada para la mayoría de los casos, por lo que se deben calcular soluciones numéricas para su resolución.
A su vez, considera toda la iluminación de la escena, incluyendo tanto luz directa como indirecta.

En cambio, la \textbf{ecuación de reflectancia} (\ref{eq:reflectance-equation}), derivada de la de renderizado, se enfoca en el cálculo de la luz indirecta.

\begin{equation}\label{eq:reflectance-equation}
    L_o(p, \omega_o) = \int_{\Omega}{f(p, \omega_i, \omega_o) L_i(p, \omega_i) n \cdot \omega_i d\omega_i}
\end{equation}

Calcula la radiancia saliente $L_o$ de un punto $p$ y un pequeño ángulo sólido $\omega_o$ como una integral sobre el hemisferio $\Omega$ centrado en el punto.
Sus términos son muy parecidos a los de la ecuación \ref{eq:rendering-equation}.
Vemos que ya no están ni el término geométrico, dado que se trata de direcciones y no puntos, ni el término de emisión, dado que solo se considera luz indirecta.
$f$ es la BRDF.
$L_i(p, \omega_i)$ es la radiancia entrante hacia $p$ por otra dirección $\omega_i$.
$n$ es la normal en el punto $p$ y $n \cdot \omega_i$ es el producto interno entre la normal y la dirección, que equivale al coseno del ángulo entre ellos.
La radiancia saliente es la suma por todo el hemisferio visible $\Omega$ centrado en $p$.
La suma de todas las radiancias a lo largo del hemisferio es la irradiancia, como se vio anteriormente.

Se procede a explorar más detalladamente la función $f$.

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{}
%     \caption{Hemisferio centrado en un punto $p$}
%     \label{fig:hemisphere}
% \end{figure}

\section{BRDF}\label{sec:brdf}

La \textbf{función de distribución de reflectancia bidireccional} (BRDF, por sus siglas en inglés), es una función $f(x, \omega, \omega')$ que dado un punto $x$, una dirección $\omega$ entrante y una saliente $\omega'$, retorna cuánta luz se refleja desde la dirección entrante hacia la saliente en el punto.

Es una característica del material que se puede obtener usando tanto modelos analíticos como midiendo objetos reales con cámaras calibradas y fuentes de luz.
A lo largo de los años, se han propuesto varios BRDFs, tanto teóricos como empíricos \cite{review-of-brdf-models}.
Los BRDFs son propios de los materiales, y este es uniforme a lo largo de todo el material, por lo que no se diferencia entre dos puntos distintos $x$ y $x'$ del mismo material.

% TODO: Agregar una foto de la máquina utilizada para medir BRDFs
% TODO: Podemos hablar más de cómo se representan capaz

Dos modelos teóricos e ideales comúnmente utilizados son los siguientes:

\begin{itemize}
    \item Reflexión especular: $f(x, \omega, \omega') = \rho$ cuando $\omega$ es simétrico a $\omega'$ respecto a la normal. $0$ en otro caso.
    \item Reflexión difusa: $f(x, \omega, \omega') = \frac{\rho}{\pi}$ para todas las direcciones.
\end{itemize}

$\rho$ es la reflectividad de la superficie, es decir, la fracción de la energía reflejada con respecto a la energía incidente total.

La reflexión especular refleja un rayo solamente en un ángulo específico,
mientras que la difusa refleja la luz en todas las direcciones de igual manera.

Los modelos ideales simplifican mucho los cálculos y son físicamente posibles, aunque no existan materiales reales con estas características de reflectancia.

Las secciones anteriores presentaron un modelo para simular la luz.
Las posteriores describen algunos métodos para calcularla.

\section{Trazado de rayos (\textit{ray tracing})}\label{sec:ray-tracing}

Uno de los métodos más antiguos y populares para calcular la iluminación global es el de trazado de rayos.
Se basa en tratar a la luz como una partícula, trazar el camino que toman los rayos de luz a través de la escena y calcular reflexión, refracción y absorción del rayo cuando interseca con un objeto.
La popularidad de este método surge debido a su simplicidad y al gran realismo que agrega a las imágenes generadas.
Su primer uso como herramienta de computación gráfica para representar reflexión, refracción y sombras se atribuye a Turner Whitted, \cite{whitted-1980}.

\textit{Ray tracing} lanza rayos desde la cámara a través de la grilla de píxeles hacia la pantalla.
Por cada rayo, se busca la intersección con el objeto más próximo.
El punto de intersección se prueba si está en sombra lanzando un nuevo rayo hacia todas las luces de la escena y comprobando si intersecan con algún objeto.
Pueden surgir otros rayos desde la intersección.
Si la superficie es especular, se genera un rayo en la dirección simétrica a la dirección de vista.
Si la superficie es transparente, se genera un rayo en la dirección de refracción, gobernada por la ley de Snell\footnote{$n_1 \sin{\theta_1} = n_2 \sin{\theta_2}$}.
En la Figura \ref{fig:whitted-ray-tracing} se puede ver una imagen generada por este método.

El método sufre de \textit{aliasing}, los bordes escalonados o ``dentados'' presentes en la figura, que ocurre debido a una falta de resolución, cantidad de píxeles, que no logra capturar todo el detalle de la imagen.
Suele notarse al representar curvas (ver Figura \ref{fig:whitted-ray-tracing-aliasing}).

% TODO: Agregar diagramas de 1) sombra, 2) reflexión y 3) refracción.

\begin{figure}
    \begin{center}
    \begin{subfigure}{.69\textwidth}
        \includegraphics[width=\textwidth]{whitted-ray-tracing.png}
        \caption{Escena entera.}
    \end{subfigure}
    \begin{subfigure}{.3\textwidth}
        \includegraphics[width=\textwidth]{whitted-aliasing.png}
        \caption{\textit{Aliasing}}
        \label{fig:whitted-ray-tracing-aliasing}
    \end{subfigure}
    \caption{Escena renderizada con el trazado de rayos de Whitted. Implementación propia. \url{https://github.com/sncalvo/whittedrenderer}.}
    \label{fig:whitted-ray-tracing}
    \end{center}
\end{figure}

Kajiya propuso en 1986\cite{rendering-equation}, junto con la ecuación de renderizado, un método llamado \textit{path tracing}, una extensión de \textit{ray tracing} que utiliza integración de Monte Carlo para simular la dispersión de la luz.
En lugar de únicamente trazar los caminos de reflexión y refracción si corresponden, muestrea aleatoriamente todos los posibles caminos de la luz, esto incluye caminos en los que la luz se dispersa.
Es imposible muestrear todos los caminos posibles de la luz, por lo que un parámetro importante en este tipo de algoritmos es la cantidad de muestras tomadas.
Debido a la varianza del muestreo aleatorio, el método sufre de ruido, un granulado en la imagen final.
El mismo disminuye a medida que se toman más muestras.

% TODO: Imagen generada con path tracing y ruido

Tanto el \textit{aliasing} como el ruido pueden mitigarse con una técnica llamada \textit{supersampling} \cite{whitted-1980}. % TODO: Buscar un artículo todo sobre aliasing o supersampling
Consiste en tomar más de una muestra por píxel, lo que implica lanzar más de un rayo por píxel y luego promediar los resultados.
Promediar las muestras suaviza las curvas, mitigando el \textit{aliasing}, y provee más muestras aleatorias para la integración de Monte Carlo, lo que reduce el ruido.
Es una técnica muy costosa dado que implica lanzar cantidades mucho mayores de rayos.
Para imágenes complejas, pueden ser necesarios cientos de rayos por píxel para reducir el ruido a niveles aceptables, imposibilitando la generación de imágenes en tiempo real.
Debido a la complejidad computacional agregada por esta técnica, han surgido otras.
La estrella de las técnicas de reducción de ruido son los \textit{denoisers} basados en el uso de redes neuronales. % TODO: Agregar una referencia sobre esto

Varios métodos de iluminación global basados en el trazado de rayos han surgido desde entonces.

\section{Trazado de conos}\label{sec:historical-cone-tracing}

En su artículo de 1984 \cite{ray-tracing-with-cones}, Amanatides propone una extensión al trazado de rayos en la que sustituye los rayos por conos.
Los rayos tienen un origen, una dirección y son infinitesimalmente finos.
Los conos tienen un origen y una dirección al igual que los rayos.
Su principal diferencia es que tienen un ángulo de apertura, lo que les agrega un grosor no despreciable.
Usando este grosor, los conos son capaces de no solo probar la existencia de intersecciones, sino también de calcular el porcentaje de área de la intersección.
El método fue propuesto para solucionar el \textit{aliasing} presente en el trazado de rayos, como alternativa al \textit{supersampling}.
En lugar de lanzar muchos rayos por cada píxel, se lanza un solo cono que integra una mayor área de la escena.
Dado que el cono tiene en cuenta la contribución de la luz de varias direcciones dentro de su volumen, reduce el \textit{aliasing} y el ruido al muestrear mayor parte de la escena y reducir la varianza del muestreo.

Trazar conos en lugar de rayos no solo ayuda en el \textit{aliasing} y el ruido, también permite generar sombras suaves.
En el trazado de rayos, como se mencionó anteriormente, al probar si un punto se encuentra en sombra o no, se lanza un rayo hacia la fuente de la luz.
Si este interseca con algún objeto antes de llegar a la luz, el punto está en sombra.
La respuesta binaria, sí o no, a la pregunta de si el punto se encuentra en sombra, resulta en sombras duras.
Al trazar un cono en lugar de un rayo hacia la fuente de luz, es posible responder el porcentaje de oclusión de ese punto, lo que produce una escala de grises y sombras suaves.
En la Figura \ref{fig:shadow-rays-and-cones} se ve un diagrama mostrando este comportamiento.

\begin{figure}
    \begin{center}
    \begin{subfigure}{.49\textwidth}
        \includegraphics[width=\textwidth]{shadow-ray-diagram}
        \caption{Rayo de sombra}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \includegraphics[width=\textwidth]{shadow-cone-diagram}
        \caption{Cono de sombra}
    \end{subfigure}
    \caption{Los conos de sombra no solo devuelven si hay intersección, también devuelven el porcentaje de área de la intersección}
    \label{fig:shadow-rays-and-cones}
    \end{center}
\end{figure}

El trazado de conos, al igual que el trazado de rayos, halla las intersecciones entre cono y objeto de manera analítica.
Se toman en cuenta los distintos tipos de objetos (esfera, plano, entre otros) y se resuelve la ecuación de intersección entre ellos.

% TODO: Poner imagen de un hemisferio partido en conos.

Para calcular la luz indirecta se halla la radiancia saliente de un punto $p$ en dirección a la cámara.
En \textit{path tracing}, este valor se calcula aproximando la integral sobre el hemisferio con el método de Monte Carlo.
Se toman varias muestras, rayos lanzados desde el punto $p$ en todas las direcciones $\omega_i$.
En el caso del trazado de conos, se particiona el hemisferio en secciones que pueden ser aproximadas mediante estos conos.

El siguiente método extiende el trazado de rayos para poder representar nuevos efectos de la luz.

% TODO: Estaría bueno hablar del método de radiosidad antes capaz.
% TODO: Se iba a llamar "Otros métodos de iluminación global" pero por ahora es uno solo jeje.
\section{Photon Mapping}\label{sec:photon-mapping}

\textit{Photon Mapping}, propuesto por Henrik Wann Jensen en 2001 \cite{photon-mapping}, es un algoritmo basado en el trazado de rayos que es capaz de simular de manera más realista la refracción de la luz a través de sustancias transparentes como el vidrio o el agua. 
Funciona ``emitiendo'' fotones de la fuente de luz y almacenando en un mapa de fotones la ubicación de cada interacción de estos con las superficies no especulares ni transparentes de la escena.

Con \textit{photon mapping} se pueden generar cáusticas, los dibujos que se generan cuando una superficie especular o transparente concentra la luz en una superficie difusa.
En la Figura \ref{fig:caustics} se puede ver este efecto.

% TODO: Estaría bueno poder usar imágenes generadas por nosotros en computación gráfica, pero no guardamos las imágenes en el repo como hicimos con whitted :c
\begin{figure}[h!]
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{photon-mapping-cornell-box-torus.png}
        \caption{Con vidrio}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{photon-mapping-cornell-box-water.png}
        \caption{Con agua}
    \end{subfigure}
    \caption{Cáusticas. Fuente: \cite{faster-photon-mapping}}
    \label{fig:caustics}
\end{figure}

El algoritmo comienza con una etapa en la que se lanzan fotones desde la fuente de luz hacia la escena.
Estos se almacenan en las superficies difusas de la escena, creando un \textbf{mapa de fotones} y se usan en una segunda etapa cuando se calcula el color de cada píxel.
Además de los rayos de ray tracing de reflexión y refracción, se lanzan rayos adicionales en direcciones aleatorias que buscan en el mapa de fotones, simulando la reflexión difusa.
Es una extensión a ray tracing, que utiliza el paso adicional de lanzado y evaluación de fotones.

Al igual que con el trazado de rayos, varias mejoras y optimizaciones han surgido a lo largo de los años.
Variantes de la técnica original han sido desarrolladas haciendo uso de tarjetas gráficas, alcanzando el tiempo real \cite{real-time-photon-mapping}.
Imágenes generadas por esta técnica pueden verse en la Figura \ref{fig:real-time-photon-mapping}.

\begin{figure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{real-time-photon-mapping-direct-only.png}
        \caption{Solo luz directa.}
    \end{subfigure}
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{real-time-photon-mapping-indirect-only.png}
        \caption{Solo luz indirecta.}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{real-time-photon-mapping.png}
        \caption{Todo junto}
    \end{subfigure}
    \caption{Photon mapping en tiempo real. Fuente: \cite{real-time-photon-mapping}.}
    \label{fig:real-time-photon-mapping}
\end{figure}

Una optimización posible es la aproximación de la geometría de la escena.
Una primitiva utilizada para esto son los vóxeles.

\section{Vóxeles}\label{sec:voxels}

Un vóxel es el equivalente de un píxel en el espacio 3D.
Así como un píxel es un elemento de imagen o \textit{\textbf{pi}cture \textbf{el}ement}, un vóxel es un elemento de volumen, \textit{\textbf{vo}lume \textbf{el}ement} \cite{rtr}.
Similar a como los píxeles se ubican en una grilla que divide una superficie 2D en secciones cuadradas, los vóxeles dividen un volumen 3D en cubos.

Tradicionalmente, se usan para guardar datos volumétricos y como primitiva para renderizar una variedad de objetos.
Permiten representar volúmenes, en contraposición al triángulo, que se utiliza para representar únicamente superficies.
Son un buen candidato para renderizar volúmenes y modelos 3D como el humo, la niebla, el fuego, los huesos y el terreno, entre otros.
Algunos de estos elementos se ven en la Figura \ref{fig:voxels_for_rendering}. % TODO: Encontrar fotos más nuevas, estas se ven que son viejasas

\begin{figure}
    \begin{center}
        \begin{subfigure}{.49\textwidth}
            \centering
            \includegraphics[width=\textwidth]{voxel-smoke.png}
            \caption{Vóxeles representando humo. Fuente: \cite{voxel-smoke}.}
        \end{subfigure}
        \begin{subfigure}{.49\textwidth}
            \centering
            \includegraphics[width=\textwidth]{voxels-for-trees.png}
            \caption{Vóxeles representando vegetación. Fuente: \cite{voxels-for-trees}.}
        \end{subfigure}
    \end{center}
    \caption{Vóxeles para renderizar humo y vegetación}
    \label{fig:voxels_for_rendering}
\end{figure} % TODO: Poner una imagen mostrando cómo son los vóxeles primero. Cubitos.

% TODO: Completar con papers
% Los vóxeles también son utilizados para visualizaciones científicas.

% Además de primitiva de renderizado, los vóxeles se utilizan cada vez más para manipular datos espaciales, como en NST (\textit{Neural Style Transfer}) \cite{transport-based-neural-style-transfer}, que fue utilizado en la reciente película de Pixar \textit{Elemental} \cite{elemental-neural-style-transfer}.

Cada vóxel marca si la zona del espacio que representa está ocupada o libre.
Pueden tener más información.
Por ejemplo, en contextos médicos se usan para indicar la opacidad y densidad de un hueso.
Para el renderizado, se pueden utilizar para almacenar valores como el color o la irradiancia.
En general, no es necesario guardar la posición de un vóxel, ya que su lugar en la grilla ya lo indica.

El proceso de convertir otra representación, por ejemplo una malla de polígonos, en una estructura de vóxeles se llama \textbf{voxelización}.
Involucra intersecar la representación poligonal con la grilla de vóxeles, y marcar los vóxeles que se solapen con esta.

Algunos programas usan grillas completas de vóxeles.
Sin embargo, en la mayoría de los casos no es necesario.
En muchas aplicaciones es suficiente tener vóxeles solo en los límites entre los objetos y el espacio vacío.
Es innecesario el relleno.

Si bien más vóxeles permiten representar más detalle, esto se vuelve muy costoso rápidamente.
Es posible minimizar la cantidad de vóxeles, manteniendo el nivel de detalle, subdividiendo solo en las zonas con geometría más compleja.
Estos vóxeles utilizan una estructura de datos conocida como un \textit{octree} disperso, explicado a continuación.

\section{Octrees}\label{sec:octree}

Un \textit{octree} es una estructura de datos de ``árbol'', en la que cada nodo interno (no hoja) tiene $8$ hijos \cite{rtr}.
Suele usarse para representar datos espaciales \cite{octree-textures}.
Se puede utilizar para dividir el espacio 3D de manera jerárquica, en varios niveles.

Para construir uno, se parte de un volumen original cúbico o paralelepípedo que se divide en dos partes iguales por dimensión, resultando en $8$ octantes iguales.
En la estructura de árbol, el nodo raíz representa el volumen original y cada uno de sus $8$ hijos representa a cada octante.
Aplicando recursivamente, se divide el espacio en $8^{(n - 1)}$ secciones, donde $n$ es la cantidad de niveles del árbol, y el primer nivel tiene un solo nodo que representa toda la escena.

De manera similar, un espacio 2D se puede dividir utilizando un \textit{quadtree}, en donde cada nodo interno tiene $4$ hijos.
Los \textit{quadtrees}, al ser bidimensionales, son más fáciles de visualizar, por lo que serán utilizados a lo largo de este informe para explicar aspectos que funcionan igual tanto en ellos como en su equivalente tridimensional.
En la Figura \ref{fig:quadtree} se muestra un \textit{quadtree} en su forma de árbol y en el espacio que subdivide.

\begin{figure}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=.4\textwidth]{quadtree.png}
        \caption{Visto en su estructura de árbol, con punteros a cada hijo}
    \end{subfigure}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=.6\textwidth]{quadtree-spatial.png}
    \caption{Visto espacialmente}
    \end{subfigure}
    \caption{Quadtree}
    \label{fig:quadtree}
\end{figure}

Cuando la naturaleza de la información lo permite, se puede evitar subdividir un nodo del árbol si sus $8$ hijos tienen todos la misma información.
De esta idea surge el \textit{octree} disperso. % TODO: Crear subsección para hablar solo del octree disperso, porque es muy importante.

A la hora de voxelizar una escena, los vóxeles pueden ubicarse dentro de un \textit{octree} disperso, en lugar de en una grilla.
En este caso, los nodos no se subdividen si no hay geometría dentro de la región del espacio que representan, dado que no hay vóxeles en esa región.

% TODO: Imagen de esto

La última sección de este capítulo introduce herramientas para la programación en GPU.

\section{Ducto gráfico}\label{sec:graphics-pipeline}

Dada una escena 3D, una cámara virtual, varios objetos y varias fuentes de luz, ¿cómo se genera una imagen 2D en el monitor de una computadora?

Si bien es posible generar una imagen a partir de una escena usando la CPU, las GPU, o tarjetas gráficas, están especialmente diseñadas para esto.

Las tarjetas gráficas ejecutan un \textbf{ducto gráfico} para generar las imágenes, esto es, una secuencia de transformaciones y operaciones que parten de primitivas y generan la imagen final.
Existen varios tipos de ductos gráficos, el ducto de rasterización, el de cómputo de propósito general, el de trazado de rayos, entre otros.

El ducto de rasterización, Figura \ref{fig:raster-pipeline}, es importante, dado que es utilizado en \textit{voxel cone tracing}.
Este ducto parte de vértices de mallas poligonales, aplica transformaciones, realiza pruebas de profundidad y calcula el color de cada píxel de la imagen final.

Cada paso de un ducto gráfico puede ser fijo o programable.
En el caso de que sea fijo, el mismo ya está implementado en la tarjeta gráfica.
En algunos casos, estos pasos fijos proveen parámetros para configurar su comportamiento, este es su mayor grado de libertad.
En el caso de que sea programable, se puede escribir un \textit{shader}, un programa de sombreado que ejecuta en la GPU, que implementa el paso en su totalidad, aportando una gran libertad a la hora de renderizar escenas.

Existen varias API, o interfaces, con las que se puede interactuar con una tarjeta gráfica \cite{comparison-graphics-apis}, notablemente Vulkan, Direct3D, Metal, WebGPU y OpenGL.
Todas estas permiten acceder al ducto de rasterización.

En OpenGL, por ejemplo, este ducto posee las etapas que se ven en la Figura \ref{fig:raster-pipeline} \cite{rtr}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{raster-pipeline.png}
    \caption{Ducto de rasterización. Fuente: \cite{rtr}}
    \label{fig:raster-pipeline}
\end{figure}

El desarrollador debe escribir \textit{shaders} para las etapas programables, que se pueden escribir en el lenguaje GLSL \cite{glsl-spec}.
Los \textit{shaders} son programas que ejecutan en la GPU con un alto grado de paralelización en la tarjeta gráfica.

Las etapas programables son el \textit{vertex shader} (\textit{shader} de vértices), \textit{geometry shader} (geometría), y \textit{fragment} o \textit{pixel shader} (fragmentos o píxeles).
Cada una de estas etapas pueden comunicar datos a etapas posteriores.
El resto de las etapas son fijas.

El \textit{vertex shader} toma los vértices de la geometría de la escena y los puede transformar a otro sistema de coordenadas.
En general es usado para pasar los vértices de espacio local de coordenadas a espacio global, de vista y luego proyección, lo que se logra usando tres matrices que se conocen como matriz de modelo, matriz de vista y matriz de proyección.
Un hilo es ejecutado por cada vértice de las primitivas de entrada.

El \textit{geometry shader} puede generar nuevos vértices, por lo que es útil para agregar complejidad extra a la geometría de la escena.
Aquí se ejecuta un hilo por cada primitiva de salida del \textit{vertex shader}.
Estas primitivas pueden tener más de un vértice.

Finalmente, el \textit{fragment shader} (o \textit{pixel shader}) trabaja con píxeles y no con vértices.
Es en este \textit{shader} donde se realizan los cálculos de iluminación para calcular el color de cada píxel.
Se ejecuta como mínimo un hilo por cada píxel no vacío de la imagen que se quiere generar.
Pueden ejecutarse más de uno en el caso que dos objetos aporten color al mismo píxel, en cuyo caso puede ser que uno sea descartado o pueden mezclarse los colores de ambos en caso de que presenten una opacidad menor a 1.

Otro ducto muy relevante, que es usado para implementar la mayoría del algoritmo, es el ducto de cómputo de propósito general.
Consiste en la inicialización de datos de entrada, luego la ejecución de un programa en la GPU llamado \textit{compute shader} (\textit{shader} de cómputo) y finalmente el retorno de datos hacia la CPU.
Notar que este ducto no es utilizado para generar una imagen, sino para realizar cálculos arbitrarios que toman una entrada y producen una salida, aprovechando la alta paralelización que provee la tarjeta gráfica.

% \section{Integral de rendering}

% Ya fue mencionada la ecuación de rendering \ref{eq:rendering-equation}.
% % TODO: Esto es teoría de la luz en general, ver cómo ponerlo
% Este modelo se basa en la óptica geométrica, que asume que la luz se propaga en una linea recta cuando no tiene interacción con la materia, en contraste con la óptica física, que considera la característica de onda de la luz y sus dos posibles estados de polarización.

% La energía de luz se describe por su radiancia $I(x, \omega)$.
% Describe el campo de radiación en un punto $x$, dada la dirección $\omega$.
% Se expresa en $W\cdot sr^{-1}\cdot m^{-2}$ y se define como:

% \begin{equation}
%     I(x, \omega) = \frac{dQ}{dA\cdot cos\theta\cdot d\Omega\cdot dt}
% \end{equation}

% con $Q$ la energía radiante (en Joules), $A$ el área (en $m^2$), $\theta$ el ángulo entre la dirección de la luz $\omega$ y el vector normal a la superficie, y $\Omega$ el ángulo sólido (en estereorradianes).

% La radiancia a lo largo de un rayo de luz es afectada cuando pasa por un medio participativo.
% Esta interacción entre la luz y la materia se modela con tres tipos de interacciones: emisión, absorción y dispersión.

% Emisión describe la cantidad de energía radiante de luz que se emite directamente por el medio participativo.
% Absorción es la cantidad de energía que es absorbida por el material.
% Finalmente, la dispersión describe la cantidad de energía que es dispersada por el material, cambiando la dirección de la propagación de la luz.
% La dispersión puede tanto incrementar (dispersión entrante) como reducir (dispersión saliente) la energía a lo largo del rayo.

% La ecuación de la transferencia de luz se obtiene combinando estos tres efectos:

% \begin{equation}
%     \omega \cdot \nabla_x I(x, \omega) = -\chi I(x, \omega) + \eta
% \end{equation}

% donde $\nabla_x I$ es la derivada direccional (el gradiente) de la radiancia.
% El producto escalar entre la dirección de la luz $\omega$ y el gradiente de la radiancia $\nabla_x I$ describe el gradiente tomado en la dirección de la luz.
% El término $\chi(x, \omega)$ es el coeficiente de absorción total.
% Se define como la suma de $\kappa(x, \omega)$, el verdadero coeficiente de absorción, y $\sigma(x, \omega)$, el coeficiente de dispersión saliente:

% \begin{equation}
%     \chi = \kappa + \sigma
% \end{equation}

% La razón $\frac{\sigma}{\chi}$ de coeficiente de dispersión saliente sobre coeficiente de dispersión total es el \textit{albedo}.
% Un albedo de $1$ significa que no hay absorción, hay dispersión perfecta.

% El término $\eta(x, \omega)$ de la ecuación es el coeficiente de emisión total.
% Es la suma del coeficiente de emisión real $q(x, \omega)$ y el coeficiente de dispersión entrante $j(x, \omega)$:

% \begin{equation}
%     \eta = q + j
% \end{equation}

% Mientras $\kappa$, $\sigma$ y $q$ son propiedades ópticas del material, el coeficiente de dispersión entrante $j$ tiene que ser calculado integrando la contribución de todas las direcciones entrantes de luz sobre la esfera:

% \begin{equation}
%     j(x, \omega) = \frac{1}{4\pi} \int_\Omega \sigma(x, \omega')\cdot p(x, \omega', \omega'')\cdot I(x, \omega')\cdot d\omega'
% \end{equation}

% Las contribuciones de la luz incidente $I(x, \omega')$ son pesadas por tanto el coeficiente de dispersión $q$ y una \textit{función de fase} $p(x, \omega', \omega)$ que describe la probabilidad de dispersión desde la dirección entrante $\omega'$ hacia la dirección $\omega$.

% Como usualmente consideramos la transferencia de luz a través de un solo rayo, podemos reescribir la ecuación para considerar un parametro $s$ a lo largo del rayo expresado como $x = p + s\omega$, con $p$ un punto de referencia arbitrario en el rayo:

% \begin{equation}\label{eq:light_transfer}
%     \frac{dI(s)}{ds} = -\chi(s)I(s) + \eta(s)
% \end{equation}

% En vóxel cone tracing, se usa el modelo óptico de emisión-absorción, descrito en \cite{real-time-volume-graphics}.
% En este modelo, se ignora la dispersión y la iluminación indirecta, representando solo emisión y absorción.
% La ecuación \ref{eq:light_transfer} queda:

% \begin{equation}
%     \frac{dI(s)}{ds} = -\kappa(s)I(s) + q(s)
% \end{equation}

% Esta ecuación se puede resolver transformandola en una integral pura entre un punto de comienzo en el rayo $s = s_0$ y un punto de fin $s = D$.
% Definimos $I_0$ como la radiancia inicial.
% La integral resultante es:

% \begin{equation}
%     I(D) = I_0\cdot e^{-\tau(s_0, D)} + \int_{s_0}^D q(s)\cdot e^{-\tau(s, D)}\cdot ds
% \end{equation}

% El término $\tau(s1, s2)$ se llama la profundidad óptica o grosor óptico.

% % TODO: Estaría bueno hablar de todas las referencias que habla el paper acá sobre luz. Completar.
% % Hay hasta un par de papers que usan vóxeles, solo un poco distinto a ellos.
% % Cuando arrancó la tésis, tendríamos que habernos mandado de una a leer todas estas referencias.
% Las mejores soluciones en terminos de velocidad trabajan en el espacio de imágen en lugar del espacio del mundo.
% vóxel cone tracing es menos eficiente que esas soluciones pero no requiere aproximaciones tan fuertes.

% % TODO: Volver a poner la parte de normlaes si realmente usamos normales.
% % Ojalá no.

% % \section{Filtrado de normales}\label{sec:normal_filtering}

% % Filtrar datos geométricos, como las normales, no es tan fácil como con colores.
% % El problema, como se muestra en la figura \ref{fig:ndf}, es que dos normales en direcciones opuestas, al ser promediadas, no representan correctamente la región conjunta.
% % Todos los enfoques para filtrar normales se basan en la idea de representar la información de las normales como una distribución estadística de direcciones.
% % Esta representación se define por una función de distribución de normales (NDF, por sus siglas en inglés), que dada una dirección, devuelve la densidad de normales para cada punto de la superficie.

% % \begin{figure}[h!]
% %     \centering
% %     \includegraphics[width=\textwidth]{figs/ndf.png}
% %     \caption{El problema filtrando normales. Fuente: \cite{normal-map-filtering}}
% %     \label{fig:ndf}
% % \end{figure}

% % \cite{toksvig} propuso una representación muy compacta para un NDF.
% % Esta representación se basa en solo una dirección media no normalizada generalmente computada con un mipmap simple de un normal map.
% % El largo de este vector media se usa como una medida de la consistencia de las direcciones normales de la superficie, y se usa para estimar la desviación estándar de una distribución Gaussiana.
